# -*- coding: utf-8 -*-
"""MomRetroM2Framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HVxYw9vPcJ4PFdPtHHvlDFIvrysdiwwV

**Amy Murakami Tsutsumi - A01750185**

# **Momento de Retroalimentación: Módulo 2 Uso de framework o biblioteca de aprendizaje máquina para la implementación de una solución. (Portafolio Implementación)**

Para este portafolio de implementación se utilizará el dataset de "Heart Failure Prediction Dataset" que se obtuvo de la siguiente liga: 
https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction

Este dataset contiene información con atributos que se utilizarán para determinar y predecir si una persona es propensa a tener un ataque cardiaco. Estos atributos son: 
1. Age: edad del paciente 
2. Sex: sexo del paciente [M: Hombre, F: Mujer]
3. ChestPainType: tipo de dolor en el pecho [TA: Angina típica, ATA: Angina atípica, NAP: Dolor no anginoso, ASY: Asintomático]
4. RestingBP: presión arterial en reposo [mm Hg]
5. Cholesterol: colesterol sérico [mm/dl]
6. FastingBS: glucemia en ayunas [1: si FastingBS > 120 mg/dl, 0: en caso contrario]
7. RestingECG: resultados del electrocardiograma [Normal: Normal, ST: con anormalidad de la onda ST-T (inversiones de la onda T y/o elevación o depresión del ST de > 0,05 mV), HVI: que muestra hipertrofia ventricular izquierda probable o definitiva según los criterios de Estes].
8. MaxHR: frecuencia cardíaca máxima alcanzada [Valor numérico entre 60 y 202]
9. ExerciseAngina: angina inducida por el ejercicio [Y: Sí, N: No]
10. Oldpeak: oldpeak = ST [Valor numérico medido en depresión]
11. ST_Slope: la pendiente del segmento ST máximo del ejercicio [Up: pendiente ascendente, Flat: plano, Down: pendiente descendente]
12. HeartDisease: clase de salida [1: enfermedad cardiaca, 0: Normal]

Este dataset cuenta con 918 registros de pacientes.

El algoritmo que se utilizará para este análisis es el de redes neuronales utilizando la librería sklearn.neural_network.

### **Lectura de Datos**
"""

# Commented out IPython magic to ensure Python compatibility.
"""
from google.colab import drive
drive.mount("/content/gdrive") 
# %cd "/content/gdrive/MyDrive/Séptimo Semestre/Mod2"
"""

"""Las librerías que se utilizarán son: 
* *pandas* : Para la creación y operaciones de dataframes.
* *numpy* : Para la creación de vectores y matrices.
* *sklearn.neural_network - MLPClassifier* : Para la implementación del algoritmo de redes neuronales. 
* *sklearn.preprocessing - StandardScaler* : Para el escalamiento de datos.
* *sklearn.model_selection - train_test_split* : Para la división de los datos en subconjuntos de entrenamiento y prueba.
* *sklearn.metrics - confusion_matrix & classification_report* : Para la visualización de desempeño del algoritmo y las métricas de clasificación.
* *matplotlib.pyplot* : Para la generación de gráficos.
* *seaborn* : Basada en matplotlib para la graficación de datos estadísticos.

"""

# Librerías
import pandas as pd
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
df = pd.read_csv('heart.csv')

"""### **Entendimiento de los datos**"""

df.head()

"""#### Visualización de los datos"""

# Visualizar las personas que son propensas a enfermedades cardiacas. 
sns.countplot(df['HeartDisease'])

"""La gráfica anterior muestra la cantidad de pacientes que tienen y los que no tienen enfermedades cardiacas. """

# HeartDisease por columna
cols = ['Sex', 'ChestPainType', 'RestingECG', 'FastingBS', 'ExerciseAngina', 'ST_Slope']

n_rows = 2
n_cols = 3

# Tamaño de la gráfica
fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.2,n_rows*3.2))

for r in range(0,n_rows):
    for c in range(0,n_cols):  
        
        i = r*n_cols+ c # indice     
        ax = axs[r][c] # Posición de cada subplot
        sns.countplot(df[cols[i]], hue=df["HeartDisease"], ax=ax, palette="BuPu")
        ax.set_title(cols[i])
        ax.legend(title="HeartDisease", loc='upper right') 
        
plt.tight_layout()

"""Las gráficas anteriores muestran la relación de los datos cualitativos con el valor real (HeartDisease). Podemos notar que a simple vista todos los atributos cualitativos tienen importancia para la predicción que se realizará más adelante. """

sns.set()
sns.pairplot(df, hue='HeartDisease', size=1.5, palette="CMRmap_r");

"""Las gráficas muestran la relación entre los valores cuantitativos con el valor real (HeartDisease). A simple vista podemos notar que todas los atributos cuantitativos son importantes para realizar las predicciones.

#### Análisis de los datos
"""

df.info()

"""Como se puede observar, existen atributos no numéricos como: Sex, ChestPainType, RestingECG, ExerciseAngina y ST_Slope que se deberán converitr en valores numéricos. """

# Obtenemos el total de los valores nulos y los ordenamos de mayor a menor
total = df.isnull().sum().sort_values(ascending=False)
print(total)

"""Ya que no existen valores nulos, no es necesario realizar una limpieza de valores NAN.

Ahora visualizaremos el comportamiento y las correlaciones que existen en los datos. 
"""

# Matriz de Correlación
corr = df.corr()
corr.style.background_gradient(cmap='coolwarm')

"""Al analizar esta matriz de correlación podemos notar que los atributos que tienen mayor correlación con HeartDisease son MaxHR y Oldpeak. Sin embargo, al no contar con un dataset con puros datos numéricos se están omitiendo varios atributos.

### **Preprocesamiento**

Ahora se convertiran las variables cualitativas en cuantitativas para poder utilizarlas en las predicciones.
"""

# Cuantificar las variables no numéricas
dummy_Sex = pd.get_dummies(df['Sex'], prefix='Sex')
dummy_ChestPainType = pd.get_dummies(df['ChestPainType'])
dummy_RestingECG = pd.get_dummies(df['RestingECG'])
dummy_ExerciseAngina = pd.get_dummies(df['ExerciseAngina'], prefix="ExAn")
dummy_STSlope = pd.get_dummies(df['ST_Slope'])

# Concatenar las nuevas columnas
dfHeart = pd.concat([df, dummy_Sex, dummy_ChestPainType, dummy_RestingECG, 
                          dummy_ExerciseAngina, dummy_STSlope], axis=1)
dfHeart = dfHeart.drop(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope', 'Sex_F', 'ExAn_N'], axis=1)
dfHeart.head()

"""La tabla anterior muestra todos los atributos con valores cuantitativos. Por lo tanto, volveremos a realizar la matriz de correlación para considerar los nuevos datos. """

corr = dfHeart.corr()
corr.style.background_gradient(cmap='coolwarm')

"""La matriz indica que los atributos con mayor correlación con HeartDisease son ASY, Flat y Up.

### **Escalamiento de datos**

Ahora se realizará el escalamiento de datos para que los modelos puedan encontrar facilmente convergencia entre los datos. Esto se realiza con fin de optimizar el método.
"""

# Separar el dataframe 
df_x = dfHeart.drop(['HeartDisease'] ,axis=1)
df_y = dfHeart['HeartDisease']

# Escalamiento 
escalador_fill = StandardScaler()
escalador_fill.fit(df_x)
dt_x = pd.DataFrame(escalador_fill.transform(df_x))

#Modularización del data-set
x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.25, train_size = 0.75, random_state= 2)

"""### **Modelos de predicción**

Ahora se realizarán 5 modelos diferentes de redes neuronales para encontrar el más eficiente.
"""

modelo1 = MLPClassifier(random_state = 1,
                                  hidden_layer_sizes = (5),
                                  activation = "relu",
                                  verbose = False,
                                  solver = "adam",
                                  learning_rate = "adaptive", 
                                  max_iter = 10000)

modelo2 = MLPClassifier(random_state = 1,
                                  hidden_layer_sizes = (10, 9),
                                  activation = "relu",
                                  verbose = False,
                                  solver = "adam",
                                  learning_rate = "adaptive", 
                                  max_iter = 10000)

modelo3 = MLPClassifier(random_state = 1,
                                  hidden_layer_sizes = (10, 8, 10),
                                  activation = "relu",
                                  verbose = False,
                                  solver = "adam",
                                  learning_rate = "adaptive", 
                                  max_iter = 10000)

modelo4 = MLPClassifier(random_state = 1,
                                  hidden_layer_sizes = (10, 15, 10, 4),
                                  activation = "relu",
                                  verbose = False,
                                  solver = "adam",
                                  learning_rate = "adaptive", 
                                  max_iter = 10000)

modelo5 = MLPClassifier(random_state = 1,
                                  hidden_layer_sizes = (10, 9, 9, 10),
                                  activation = "relu",
                                  verbose = False,
                                  solver = "adam",
                                  learning_rate = "adaptive", 
                                  max_iter = 10000)

modelo1.fit(x_train, y_train)
modelo2.fit(x_train, y_train)
modelo3.fit(x_train, y_train)
modelo4.fit(x_train, y_train)
modelo5.fit(x_train, y_train)

print("Training score modelo 1: ", modelo1.score(x_train,y_train))
print("Test score modelo 1: ", modelo1.score(x_test, y_test))
print("\nTraining score modelo 2: ", modelo2.score(x_train,y_train))
print("Test score modelo 2: ", modelo2.score(x_test, y_test))
print("\nTraining score modelo 3: ", modelo3.score(x_train,y_train))
print("Test score modelo 3: ", modelo3.score(x_test, y_test))
print("\nTraining score modelo 4: ", modelo4.score(x_train,y_train))
print("Test score modelo 4: ", modelo4.score(x_test, y_test))
print("\nTraining score modelo 5: ", modelo5.score(x_train,y_train))
print("Test score modelo 5: ", modelo5.score(x_test, y_test))

"""Podemos visualizar que los modelos 1, 3 y 4 son los más precisos con los datos de entrenamiento. Sin embargo, el modelo más preciso con los datos de prueba es el modelo 4.

### **Predicciones**

Ahora se realizarán las predicciones de los cinco modelos.
"""

pred1 = modelo1.predict(x_test)
pred2 = modelo2.predict(x_test)
pred3 = modelo3.predict(x_test)
pred4 = modelo4.predict(x_test)
pred5 = modelo5.predict(x_test)

#Modelo 1
print('Modelo 1: ')
print(modelo1.predict_proba([df_x.loc[0]]))
print('Heart Disease? Estimated: ', modelo1.predict([df_x.loc[0]]),
      'Real: ', df_y.loc[0])
#Modelo 2
print('\nModelo 2: ')
print(modelo2.predict_proba([df_x.loc[0]]))
print('Heart Disease? Estimated: ', modelo2.predict([df_x.loc[0]]),
      'Real: ', df_y.loc[0])
#Modelo 3
print('\nModelo 3: ')
print(modelo3.predict_proba([df_x.loc[0]]))
print('Heart Disease? Estimated: ', modelo3.predict([df_x.loc[0]]),
      'Real: ', df_y.loc[0])
#Modelo 4
print('\nModelo 4: ')
print(modelo4.predict_proba([df_x.loc[0]]))
print('Heart Disease? Estimated: ', modelo4.predict([df_x.loc[0]]),
      'Real: ', df_y.loc[0])
#Modelo 5
print('\nModelo 5: ')
print(modelo5.predict_proba([df_x.loc[0]]))
print('Heart Disease? Estimated: ', modelo5.predict([df_x.loc[0]]),
      'Real: ', df_y.loc[0])

"""Podemos observar que en todos los modelos se está realizando la predicción de manera correcta. Como primer valor muestra la probabilidad de que el HeartDisease tenga un valor de 0 y 1. Después se muestra el valor estimado con los modelos y el valor real. En todos los modelos coinciden que el valor estimado por cada modelo y el valor real es 0, por lo que se puede confirmar que son modelos efectivos para la predicción de enfermedades cardiacas.

### **Validación**

Para la etapa de validación se utilizarán matrices de confusión y reportes de clasificación.
"""

#Modelo 1
print('Modelo 1: ')
sns.set()
f, ax = plt.subplots()
matriz1 = confusion_matrix(y_test,pred1)
print(classification_report(y_test,pred1))
print('\nMatriz de confusión: ')
sns.heatmap(matriz1, annot=True, ax=ax, cbar=False, fmt='g', cmap='Dark2_r')

"""Para el primer modelo podemos observar que el valor de f1-score es 0.81 lo que indica que es un buen modelo de predicción. Por otro lado, en la matriz de confusión se tienen 80 valores true positive y 107 valores true negative; es decir, valores predecidos que coinciden con el valor real. Además, se tienen 29 valores false positive y 14 false negative es decir valores erróneos."""

#Modelo 2
print('Modelo 2: ')
sns.set()
f, ax = plt.subplots()
matriz2 = confusion_matrix(y_test,pred2)
print(classification_report(y_test,pred2))
print('\nMatriz de confusión: ')
sns.heatmap(matriz2, annot=True, ax=ax, cbar=False, fmt='g', cmap='Paired')

"""Para el segundo modelo podemos observar que el valor de f1-score es 0.84 lo que indica que es un mejor modelo de predicción que el primero. Por otro lado, en la matriz de confusión se tienen 94 valores true positive y 99 valores true negative; es decir, valores predecidos que coinciden con el valor real. Además, se tienen 15 valores false positive y 22 false negative es decir valores erróneos."""

#Modelo 3
print('Modelo 3: ')
sns.set()
f, ax = plt.subplots()
matriz3 = confusion_matrix(y_test,pred3)
print(classification_report(y_test,pred3))
print('\nMatriz de confusión: ')
sns.heatmap(matriz3, annot=True, ax=ax, cbar=False, fmt='g', cmap='Pastel1')

"""Para el tercer modelo podemos observar que el valor de f1-score es 0.83 lo que indica que es un buen modelo, pero no tiene la misma precisión que el segundo. Por otro lado, en la matriz de confusión se tienen 82 valores true positive y 110 valores true negative; es decir, valores predecidos que coinciden con el valor real. Además, se tienen 27 valores false positive y 11 false negative es decir valores erróneos."""

#Modelo 4
print('Modelo 4: ')
sns.set()
f, ax = plt.subplots()
matriz4 = confusion_matrix(y_test,pred4)
print(classification_report(y_test,pred4))
print('\nMatriz de confusión: ')
sns.heatmap(matriz4, annot=True, ax=ax, cbar=False, fmt='g', cmap='Pastel2')

"""Para el cuarto modelo podemos observar que el valor de f1-score es 0.85 lo que indica que es el mejor modelo hasta ahora. Por otro lado, en la matriz de confusión se tienen 87 valores true positive y 109 valores true negative; es decir, valores predecidos que coinciden con el valor real. Además, se tienen 22 valores false positive y 12 false negative es decir valores erróneos."""

#Modelo 5
print('Modelo 5: ')
sns.set()
f, ax = plt.subplots()
matriz5 = confusion_matrix(y_test,pred5)
print(classification_report(y_test,pred5))
print('\nMatriz de confusión: ')
sns.heatmap(matriz5, annot=True, ax=ax, cbar=False, fmt='g', cmap='PuRd')

"""Por último, para el cuarto modelo podemos observar que el valor de f1-score es 0.83 lo que indica que es un buen modelo, pero no el mejor. Por otro lado, en la matriz de confusión se tienen 87 valores true positive y 104 valores true negative; es decir, valores predecidos que coinciden con el valor real. Además, se tienen 22 valores false positive y 17 false negative es decir valores erróneos."""

fig, ax =plt.subplots(1,2)
sns.countplot(pred4, ax=ax[0], palette="Accent")
sns.countplot(y_test, ax=ax[1], palette="RdBu_r")
fig.show()

"""En la gráfica anterior se muestra del lado izquierdo los número de valores predecidos con el modelo cuatro y del lado derecho los valores reales. Se puede observar que los datos predecidos se acercan bastante a los valores reales."""